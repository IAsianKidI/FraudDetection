{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r7k5qdyHLFSd"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2XbHCQKSLREn"
      },
      "outputs": [],
      "source": [
        "# Feedforward Neural Network\n",
        "class FNN():\n",
        "  # this method is a constructor and is used to create an instance of the feedforward neural network model containing the training data\n",
        "  # parameters\n",
        "  # learning_rate: this contains a float which is used to change how big of a jump the data will make\n",
        "  # epoch: this contains a integer which is used to repeat the training epoch times\n",
        "  # x: this contains the training dataset examples\n",
        "  # y: this contains the training dataset answers\n",
        "  def __init__(self, learning_rate, epoch, x, y):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epoch = epoch\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.number_data, self.number_feature = x.shape\n",
        "    self.input_weights = np.zeros((self.number_feature, 4))\n",
        "    self.bias = 1\n",
        "    self.bias_hidden = 1\n",
        "    self.bias_output = 1\n",
        "    self.hidden_weights = np.zeros(4)\n",
        "    self.hidden_weights2 = np.zeros((4, 4))\n",
        "\n",
        "  # this method is used for back propagation\n",
        "  # parameters\n",
        "  # input_hidden2: this contains an array that contains the input to hidden values but with relu applied to it\n",
        "  # hidden2_hidden: this contains an array that contains the hidden to hidden values but with relu applied to it\n",
        "  # output_output: this contains an array that contains the hidden to output values but with sigmoid applied to it\n",
        "  def backward_pass(self, input_hidden2, hidden2_hidden,hidden_output):\n",
        "    # Calculate errors\n",
        "    # x\n",
        "    output_error = hidden_output - self.y\n",
        "    # x by 4\n",
        "    hidden_error = np.outer(output_error, self.hidden_weights)\n",
        "    # x by 4\n",
        "    hidden_error2 = np.dot(hidden_error, self.hidden_weights2)\n",
        "\n",
        "    # Calculating gradients. x by 4\n",
        "    output_weights_gradient = (1/self.number_data) * np.dot(hidden2_hidden.T, output_error)\n",
        "    output_grad_bias = (1/self.number_data) * np.sum(output_error)\n",
        "\n",
        "    # x by 4\n",
        "    hidden_weights_gradient = (1/self.number_data) * np.dot(input_hidden2.T, hidden_error)\n",
        "    hidden_grad_bias = (1/self.number_data) * np.sum(hidden_error)\n",
        "\n",
        "    # 4 by features\n",
        "    hidden_weights_gradient2 = (1/self.number_data) * np.dot(self.x.T, hidden_error2)\n",
        "    hidden_grad_bias2 = (1/self.number_data) * np.sum(hidden_error2)\n",
        "\n",
        "    # Updating weights and biases\n",
        "    self.hidden_weights -= self.learning_rate * output_weights_gradient\n",
        "    self.bias_output -= self.learning_rate * output_grad_bias\n",
        "\n",
        "    self.hidden_weights2 -= self.learning_rate * hidden_weights_gradient\n",
        "    self.bias_hidden -= self.learning_rate * hidden_grad_bias\n",
        "\n",
        "    self.input_weights -= self.learning_rate * hidden_weights_gradient2\n",
        "    self.bias -= self.learning_rate * hidden_grad_bias2\n",
        "\n",
        "\n",
        "  # trains the model\n",
        "  def fit(self):\n",
        "    for p in range(self.epoch):\n",
        "\n",
        "      # input to hidden. x by 4\n",
        "      hidden_input = np.dot(self.x, self.input_weights) + self.bias\n",
        "      # x by 4\n",
        "      relu_activation = np.maximum(0, hidden_input)\n",
        "\n",
        "      # hidden2 to hidden. x by 4\n",
        "      hidden_input2 = np.dot(relu_activation, self.hidden_weights2) + self.bias_hidden\n",
        "      # x by 4\n",
        "      relu_activation2 = 1 / (1 + np.exp(-hidden_input2))\n",
        "\n",
        "      # hidden to output using sigmoid since it is a binary classification. x\n",
        "      output_hidden = np.dot(relu_activation2, self.hidden_weights) + self.bias_output\n",
        "      # x\n",
        "      Sigmoid = 1 / (1 + np.exp(-output_hidden))\n",
        "      # gradiants\n",
        "      self.backward_pass(relu_activation, relu_activation2, Sigmoid)\n",
        "\n",
        "\n",
        "  # finds the accuracy with the testing dataset\n",
        "  # parameters\n",
        "  # x_test: contains the testing dataset examples\n",
        "  # y_test: contains the testing dataset answers\n",
        "  def accuracy(self, x_test, y_test):\n",
        "    # calculate the outputs\n",
        "    hidden_input = np.dot(x_test, self.input_weights) + self.bias\n",
        "    relu_activation = np.maximum(0, hidden_input)\n",
        "\n",
        "    # hidden2 to hidden. x by 4\n",
        "    hidden_input2 = np.dot(relu_activation, self.hidden_weights2) + self.bias_hidden\n",
        "    # x by 4\n",
        "    relu_activation2 = 1 / (1 + np.exp(-hidden_input2))\n",
        "\n",
        "    # hidden to output\n",
        "    output_hidden = np.dot(relu_activation2, self.hidden_weights) + self.bias_output\n",
        "    Sigmoid = 1 / (1 + np.exp(-output_hidden))\n",
        "\n",
        "    accuracy = 0\n",
        "    # finds accuracy\n",
        "    for i in range(len(Sigmoid)):\n",
        "      # uses the threshold to determine if it is 1 or 0\n",
        "      if Sigmoid[i] > .5:\n",
        "        # checks if the guess was correct, if it was increment by 1\n",
        "        if y_test[i] == 1:\n",
        "          accuracy += 1\n",
        "      else:\n",
        "        # checks if the guess was correct, if it was increment by 1\n",
        "        if y_test[i] == 0:\n",
        "          accuracy += 1\n",
        "\n",
        "    # returns the percentage\n",
        "    return (accuracy / len(y_test)) * 100\n",
        "  \n",
        "  # this method will save the weights of the model into a python file\n",
        "    def saveWeights(self):\n",
        "        # this is a data type that stores key pair values so it stores w1 with the w1 weights\n",
        "        save = {\n",
        "            \"w1\": self.w1,\n",
        "            \"w2\": self.w2\n",
        "        }\n",
        "\n",
        "        # opens the json file in write mode and closes it when finished\n",
        "        with open(\"save.json\", \"w\") as f:\n",
        "            # stores save in the json file\n",
        "            json.dump(save, f)\n",
        "\n",
        "\n",
        "    # this method will load the weights of the model into the code\n",
        "    def loadWeights(self):\n",
        "        # opens the json file in read mode and closes it when finished\n",
        "        with open(\"save.json\", \"r\") as f:\n",
        "            # loads what is stored in the json file into the save\n",
        "            save = json.load(f)\n",
        "            # set the weights stored in save\n",
        "            self.w1 = save[\"w1\"]\n",
        "            self.w2 = save[\"w2\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "    x = df.drop(columns=['merchant','first','last','gender','street','city','state','zip','job','dob','trans_num','unix_time','trans_date_trans_time','cc_num'])\n",
        "    # y = df['is_fraud']\n",
        "    dataset=x\n",
        "    # dataset = np.column_stack((x, y))\n",
        "    #np.random.shuffle(dataset)\n",
        "    # Split data\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    train_dataset, test_dataset = dataset[:train_size], dataset[train_size:]\n",
        "    #features\n",
        "    train_dataset=np.delete(train_dataset,0,axis=1)\n",
        "    test_dataset=np.delete(test_dataset,0,axis=1)\n",
        "    #targets\n",
        "    train_target=train_dataset[:,7]\n",
        "    test_target=test_dataset[:,7]\n",
        "\n",
        "    train_dataset=np.delete(train_dataset,7,axis=1)\n",
        "    test_dataset=np.delete(test_dataset,7,axis=1)\n",
        "\n",
        "    return train_dataset, test_dataset, train_target, test_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------FNN-----------------------------------\n",
            "Accuracy: 99.4732542208009\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "#output get_data\n",
        "train_sample,test_sample,train_target,test_target=get_data('fraudTrain.csv')\n",
        "\n",
        "train_sample_scaled = scaler.fit_transform(train_sample)\n",
        "test_sample_scaled = scaler.transform(test_sample)\n",
        "\n",
        "# Feedforward Neural Networks running\n",
        "print(\"-----------------------------------FNN-----------------------------------\")\n",
        "Feedforward_Neural_Network = FNN(0.1, 100, train_sample_scaled, train_target)\n",
        "Feedforward_Neural_Network.fit()\n",
        "print(\"Accuracy:\",Feedforward_Neural_Network.accuracy(test_sample_scaled, test_target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# reshape so it can match the input shape of the model\n",
        "X_train_reshaped = np.reshape(train_sample_scaled, (train_sample_scaled.shape[0], 1, train_sample_scaled.shape[1]))\n",
        "X_test_reshaped = np.reshape(test_sample_scaled, (test_sample_scaled.shape[0], 1, test_sample_scaled.shape[1]))\n",
        "\n",
        "# creates the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(1, 30)))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# compiles the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# trains the model\n",
        "history = model.fit(X_train_reshaped, train_target, epochs=1000, verbose=2)\n",
        "\n",
        "# evaluates the model\n",
        "loss = model.evaluate(X_test_reshaped, train_sample,test_sample,train_target,test_target=get_data('fraudTrain.csv')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "# Train the model on training data\n",
        "rf.fit(X_train_reshaped, train_target);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = rf.predict(X_test_reshaped)\n",
        "\n",
        "accuracy = 0\n",
        "# finds accuracy\n",
        "for i in range(len(y_pred)):\n",
        "  # uses the threshold to determine if it is 1 or 0\n",
        "  if y_pred[i] > .5:\n",
        "    # checks if the guess was correct, if it was increment by 1\n",
        "    if test_target[i] == 1:\n",
        "      accuracy += 1\n",
        "  else:\n",
        "    # checks if the guess was correct, if it was increment by 1\n",
        "    if test_target[i] == 0:\n",
        "      accuracy += 1\n",
        "\n",
        "accuracy = (accuracy / len(test_target)) * 100\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
