{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r7k5qdyHLFSd"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "x = data.data\n",
        "y = data.target\n",
        "features = data.feature_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=3)\n",
        "\n",
        "# this scales the data so it is easier to work with, in this case to prevent the data from going to undefined since the numbers can get very small without scaling it\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "c5E7PkB2LJ7x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feedforward Neural Network\n",
        "class FNN():\n",
        "  # this method is a constructor and is used to create an instance of the feedforward neural network model containing the training data\n",
        "  # parameters\n",
        "  # learning_rate: this contains a float which is used to change how big of a jump the data will make\n",
        "  # epoch: this contains a integer which is used to repeat the training epoch times\n",
        "  # x: this contains the training dataset examples\n",
        "  # y: this contains the training dataset answers\n",
        "  def __init__(self, learning_rate, epoch, x, y):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epoch = epoch\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.number_data, self.number_feature = x.shape\n",
        "    self.input_weights = np.zeros((self.number_feature, 4))\n",
        "    self.bias = 1\n",
        "    self.bias_output = 1\n",
        "    self.hidden_weights = np.zeros(4)\n",
        "\n",
        "  # this method is used for back propagation\n",
        "  # parameters\n",
        "  # hidden_input: this contains an array that contains the input values combined with their weights\n",
        "  # hidden_output: this contains an array that contains the hidden_input values but with relu applied to it\n",
        "  # output_input: this contains an array that contains the hidden values combined with their weights\n",
        "  # output_output: this contains an array that contains the output_input values but with sigmoid applied to it\n",
        "  def backward_pass(self, hidden_input, hidden_output, output_input, output_output):\n",
        "    # Calculate errors\n",
        "    output_error = output_output - self.y\n",
        "    hidden_error = np.outer(output_error, self.hidden_weights)\n",
        "\n",
        "    # Calculating gradients\n",
        "    output_weights_gradient = (1/self.number_data) * np.dot(hidden_output.T, output_error)\n",
        "    output_grad_bias = (1/self.number_data) * np.sum(output_error)\n",
        "    hidden_weights_gradient = (1/self.number_data) * np.dot(self.x.T, hidden_error)\n",
        "    hidden_grad_bias = (1/self.number_data) * np.sum(hidden_error)\n",
        "\n",
        "    # Updating weights and biases\n",
        "    self.hidden_weights -= self.learning_rate * output_weights_gradient\n",
        "    self.bias_output -= self.learning_rate * output_grad_bias\n",
        "    self.input_weights -= self.learning_rate * hidden_weights_gradient\n",
        "    self.bias -= self.learning_rate * hidden_grad_bias\n",
        "\n",
        "  # trains the model\n",
        "  def fit(self):\n",
        "    for p in range(self.epoch):\n",
        "      # input to hidden\n",
        "      hidden_input = np.dot(self.x, self.input_weights) + self.bias\n",
        "      relu_activation = np.maximum(0, hidden_input)\n",
        "\n",
        "      # hidden to output using sigmoid since it is a binary classification\n",
        "      output_hidden = np.dot(relu_activation, self.hidden_weights) + self.bias_output\n",
        "      Sigmoid = 1 / (1 + np.exp(-output_hidden))\n",
        "\n",
        "      # gradiants\n",
        "      self.backward_pass(hidden_input, relu_activation, output_hidden, Sigmoid)\n",
        "\n",
        "  # finds the accuracy with the testing dataset\n",
        "  # parameters\n",
        "  # x_test: contains the testing dataset examples\n",
        "  # y_test: contains the testing dataset answers\n",
        "  def accuracy(self, x_test, y_test):\n",
        "    # calculate the outputs\n",
        "    hidden_input = np.dot(x_test, self.input_weights) + self.bias\n",
        "    relu_activation = np.maximum(0, hidden_input)\n",
        "\n",
        "    # hidden to output\n",
        "    output_hidden = np.dot(relu_activation, self.hidden_weights) + self.bias_output\n",
        "    Sigmoid = 1 / (1 + np.exp(-output_hidden))\n",
        "\n",
        "    accuracy = 0\n",
        "    # finds accuracy\n",
        "    for i in range(len(Sigmoid)):\n",
        "      # uses the threshold to determine if it is 1 or 0\n",
        "      if Sigmoid[i] > .5:\n",
        "        # checks if the guess was correct, if it was increment by 1\n",
        "        if y_test[i] == 1:\n",
        "          accuracy += 1\n",
        "      else:\n",
        "        # checks if the guess was correct, if it was increment by 1\n",
        "        if y_test[i] == 0:\n",
        "          accuracy += 1\n",
        "\n",
        "    # returns the percentage\n",
        "    return (accuracy / len(y_test)) * 100"
      ],
      "metadata": {
        "id": "2XbHCQKSLREn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feedforward Neural Networks running\n",
        "print(\"-----------------------------------FNN-----------------------------------\")\n",
        "Feedforward_Neural_Network = FNN(0.1, 100, X_train_scaled, y_train)\n",
        "Feedforward_Neural_Network.fit()\n",
        "print(\"Accuracy:\",Feedforward_Neural_Network.accuracy(X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lquKcr4wLSel",
        "outputId": "acb21148-88d5-4bcb-c1d0-164175bcb944"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------FNN-----------------------------------\n",
            "Accuracy: 95.32163742690058\n"
          ]
        }
      ]
    }
  ]
}