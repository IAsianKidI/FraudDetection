{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7k5qdyHLFSd"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2XbHCQKSLREn"
      },
      "outputs": [],
      "source": [
        "# Feedforward Neural Network\n",
        "class FNN():\n",
        "  # this method is a constructor and is used to create an instance of the feedforward neural network model containing the training data\n",
        "  # parameters\n",
        "  # learning_rate: this contains a float which is used to change how big of a jump the data will make\n",
        "  # epoch: this contains a integer which is used to repeat the training epoch times\n",
        "  # x: this contains the training dataset examples\n",
        "  # y: this contains the training dataset answers\n",
        "  def __init__(self, learning_rate, epoch, x, y):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epoch = epoch\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.number_data, self.number_feature = x.shape\n",
        "    self.input_weights = np.zeros((self.number_feature, 4))\n",
        "    self.bias = 1\n",
        "    self.bias_output = 1\n",
        "    self.hidden_weights = np.zeros(4)\n",
        "\n",
        "  # this method is used for back propagation\n",
        "  # parameters\n",
        "  # hidden_output: this contains an array that contains the hidden_input values but with relu applied to it\n",
        "  # output_output: this contains an array that contains the output_input values but with sigmoid applied to it\n",
        "  def backward_pass(self, hidden_output, output_output):\n",
        "    # Calculate errors\n",
        "    output_error = output_output - self.y\n",
        "    hidden_error = np.outer(output_error, self.hidden_weights)\n",
        "\n",
        "    # Calculating gradients\n",
        "    output_weights_gradient = (1/self.number_data) * np.dot(hidden_output.T, output_error)\n",
        "    output_grad_bias = (1/self.number_data) * np.sum(output_error)\n",
        "    hidden_weights_gradient = (1/self.number_data) * np.dot(self.x.T, hidden_error)\n",
        "    hidden_grad_bias = (1/self.number_data) * np.sum(hidden_error)\n",
        "\n",
        "    # Updating weights and biases\n",
        "    self.hidden_weights -= self.learning_rate * output_weights_gradient\n",
        "    self.bias_output -= self.learning_rate * output_grad_bias\n",
        "    self.input_weights -= self.learning_rate * hidden_weights_gradient\n",
        "    self.bias -= self.learning_rate * hidden_grad_bias\n",
        "\n",
        "  # trains the model\n",
        "  def fit(self):\n",
        "    for p in range(self.epoch):\n",
        "      # input to hidden\n",
        "      hidden_input = np.dot(self.x, self.input_weights) + self.bias\n",
        "      relu_activation = np.maximum(0, hidden_input)\n",
        "\n",
        "      # hidden to output using sigmoid since it is a binary classification\n",
        "      output_hidden = np.dot(relu_activation, self.hidden_weights) + self.bias_output\n",
        "      Sigmoid = 1 / (1 + np.exp(-output_hidden))\n",
        "\n",
        "      # gradiants\n",
        "      self.backward_pass(relu_activation, Sigmoid)\n",
        "\n",
        "  # finds the accuracy with the testing dataset\n",
        "  # parameters\n",
        "  # x_test: contains the testing dataset examples\n",
        "  # y_test: contains the testing dataset answers\n",
        "  def accuracy(self, x_test, y_test):\n",
        "    # calculate the outputs\n",
        "    hidden_input = np.dot(x_test, self.input_weights) + self.bias\n",
        "    relu_activation = np.maximum(0, hidden_input)\n",
        "\n",
        "    # hidden to output\n",
        "    output_hidden = np.dot(relu_activation, self.hidden_weights) + self.bias_output\n",
        "    Sigmoid = 1 / (1 + np.exp(-output_hidden))\n",
        "\n",
        "    accuracy = 0\n",
        "    # finds accuracy\n",
        "    for i in range(len(Sigmoid)):\n",
        "      # uses the threshold to determine if it is 1 or 0\n",
        "      if Sigmoid[i] > .5:\n",
        "        # checks if the guess was correct, if it was increment by 1\n",
        "        if y_test[i] == 1:\n",
        "          accuracy += 1\n",
        "      else:\n",
        "        # checks if the guess was correct, if it was increment by 1\n",
        "        if y_test[i] == 0:\n",
        "          accuracy += 1\n",
        "\n",
        "    # returns the percentage\n",
        "    return (accuracy / len(y_test)) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "    x = df.drop(columns=['merchant','first','last','gender','street','city','state','zip','job','dob','trans_num','unix_time','trans_date_trans_time','cc_num'])\n",
        "    # y = df['is_fraud']\n",
        "    dataset=x\n",
        "    # dataset = np.column_stack((x, y))\n",
        "    #np.random.shuffle(dataset)\n",
        "    # Split data\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    train_dataset, test_dataset = dataset[:train_size], dataset[train_size:]\n",
        "    #features\n",
        "    train_dataset=np.delete(train_dataset,0,axis=1)\n",
        "    test_dataset=np.delete(test_dataset,0,axis=1)\n",
        "    #targets\n",
        "    train_target=train_dataset[:,7]\n",
        "    test_target=test_dataset[:,7]\n",
        "\n",
        "    train_dataset=np.delete(train_dataset,7,axis=1)\n",
        "    test_dataset=np.delete(test_dataset,7,axis=1)\n",
        "\n",
        "    return train_dataset, test_dataset, train_target, test_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "#output get_data\n",
        "train_sample,test_sample,train_target,test_target=get_data('fraudTrain.csv')\n",
        "\n",
        "train_sample_scaled = scaler.fit_transform(train_sample)\n",
        "test_sample_scaled = scaler.transform(test_sample)\n",
        "\n",
        "# Feedforward Neural Networks running\n",
        "print(\"-----------------------------------FNN-----------------------------------\")\n",
        "Feedforward_Neural_Network = FNN(0.1, 100, train_sample_scaled, train_target)\n",
        "Feedforward_Neural_Network.fit()\n",
        "print(\"Accuracy:\",Feedforward_Neural_Network.accuracy(test_sample_scaled, test_target))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
